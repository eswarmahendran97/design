1) Attributes in webFilter(Java)
Used for passing attribute from one filter to another filter. This attributes can be passed from filter to controller as well.

Eg:
AuthenticationFilter -> Authenticates and sends User Detail as attribute
AuthorizationFilter -> Gets the User Detail from attribute and fetch the type from it and Authorizes


2) If some exception occurs, what is best way to provide the Error status to User/Another Service?
Problem_Detail(RFC_7807) Format


3) Why you don't need to add throws when throwing a RuntimeException, but you do need to add throws when throwing a custom checked exception?
Checked exceptions: These are exceptions that the compiler forces you to handle. Checked exceptions must either be caught in a try-catch block or declared in the method's throws clause. 
Unchecked exceptions (Runtime exceptions): These are exceptions that the compiler does not force you to handle. You are not required to catch them or declare them in the method's throws clause. This is because unchecked exceptions are typically used to represent programming bugs or conditions that are not expected to be handled by the caller.

When to use:
Compile time Exception:
Eg: For retying when network issue occurs
Runtime Exception: Eg: Nullpointer for user data


4) What is Basic auth format?
Key > Basic
Value -> encoding of username and password


5) Important things to note while using Webclient
    1) Uses reactor Netty server
    2) While passing query param use Map.of() to get meaning response in case of wrong input


6) WebFilter vs Exchange Filter
Web Filter -> Used for filtering incoming request. Attributes can be passed to different filter and to controller as well
Exchnage Filter -> Used for filtering when we are making API call some other service. Attributes can be passed to different filter.


7)Json Array format vs Json line format
Json Array:
[
{"name": "Alice”},
{"name": "Bob”},
{"name": "Charlie"}
]

Json line:
{"name": "Alice"}
{"name": "Bob"}
{"name": "Charlie"}

Why we need Json line format?
Unlike the JSON array format, there is no outer array. Each line represents a separate JSON object. It is well-suited for streaming applications, where data can be processed one line at a time. This is especially useful for handling large datasets that do not fit entirely in memory. Using this we don’t want load whole data into memory. 

Eg: I need to send 1000 object to a client to process it
Using application/json -> It will sent as array of object, Client need to deserialize the whole array then he will be processing it
Using application/ndjson -> It will sent json with new line format, Client can deserialize the object one by one then he will be processing it

But using Flux with application/json will can able to process data one by one

So When to use application/ndjson
If server send large chunk of dataset to process, server using application/ndjson type can process each data one by one

when using Flux in a POST or GET request with WebFlux will connection is open for long time?
Yes, indeed you can  send and receive data asynchronously, and the connection remains open for an extended period while data is being streamed. But Thread will not be blocked


8)gZip
gZip is a widely used compression method that reduces the size of HTTP response data. 
    1) When a client (browser or application) sends an HTTP request to a server, it should include an Accept-Encoding header. 
    2) Upon receiving the request, the server checks the Accept-Encoding header to determine the client can handle compressed responses.
    3) gZip uses the DEFLATE compression method, which is a combination of Huffman coding and LZ77 compression to reduce the size of the response data and send it to client along with a Content-Encoding: gzip header.
    4) The client then decompresses the response body using the gZip algorithm once it sees the Content-Encoding: gZip header


9)OutBound port on request:
Let's say we have hosted our application on Port 8080, Which means our application is listening for incoming requests on port 8080. Here Port 8080 is used for communication when client sends request to server. But when our application is making request to another application it won't use 8080 it uses random high number port for outbound. By using random port we can reuse and have multiple connections from our source application.
so when I make 1000 concurrent request 1000 outbound ports will be open. Also In http1.x you cannot send multiple request in same TCP connection, one request and response had to finish before the next could start.

To address this you can use HTTP2. Through multiplexing, in single TCP connection multiple request can be sent as stream and can receive multiple response at same time as stream(bidirectionally).


10) Summary of Layer Roles in HTTPS:
        Layer	                    Contribution to HTTPS Connection
Transport Layer (TCP)	    Responsible for the encryption and security provided by SSL/TLS in HTTPS communication.    
Application Layer (HTTP)	Responsible for HTTPS itself, which is just HTTP over a secure connection


11) BOM (Bill of materials)
The BOM's purpose is to define a set of versions for a library that can be used across multiple projects to ensure version consistency.

If the Library is present in BOM(This Bom added in my POM file), I dont want to that Library in POM file since I can use it as transtive dependency?
BOM only manages versions - doesn't include actual dependencies. It is not packed as JAR, it packed as POM. So, Its can't be used like above.

Also while including BOM as dependency we need to specify <type>pom</type> and <scope>import</scope> below version of BOM. Also you need to add you what ever dependency you need in your application POM, just you do need to specify the version. This version wil be coming from BOM(if BOM have it).

For maiting version I can use Transtive dependency itself right by creating a wrapper application?
Lets say you wrapper have 20 dependency and adding as depedency in your application, but one of your application need only 10 of that, then why your application need to have unused remaining 10 dependency. But when you use BOM you will be specifying version and it will packed as POM not Jar.


12) BFF vs API gateway
If you are just using BFF as proxy the API gateway is enough but BFF can do many things, Eg: Without BFF you might be making 10 API server call to get a particular data but using BFF, client will make one call to BFF and BFF will make 10 calls to server so that you browser will not have more load. 

You can say I will modify in a way that my browser makes one and server process and give the data accordingly,
At any cost you server should be generic(fine-grained APIs that BFFs can compose differently for each client), it should act based in client need. What if tomorrow there comes a situation to support Mobile  Also it is advised to have one BFF for one client eg: 1 for browser and 1 for mobile

Also you can handle cache in BFF, Response transformation, Error handling etc.

Also since performance of Node.js when combining with Frontend library its good to use Node as BFF layer

When implementing Server-Sent Events (SSE) with a Backend-for-Frontend (BFF) architecture, you essentially have two tunnels or connections in play
1)Backend Server to BFF
2)BFF to Client


13) Sql vs NoSql
Sql - Structured Data and Relation between table
NoSql - Best for semi structured data

In future if your table needs to have multiple column(based on new feature) you need to do an alter table query.  But in NoSql it not needed
Also noSql has the inbuilt concept of sharing to scale horizontally. Sql is good for vertical scaling

SemiStructured Data
XML, json or key-value pair have a certain format but they do not follow a rigid, predefined schema like structured data 

Eg: Json have key-value pairs and Arrays being said that it won't follow a predefined schema

Although you can store unstructured  data (images, video, audio, raw logs, documents) in noSql db, best tool to store other it is Hadoop, HDFS etc..  because these tools are built for massive data processing and analysis. While  NoSQL db are designed for flexible, scalable data storage and retrieval

Cons of NoSql:
Eventual consistency: NoSql doesn't guarantee that all reads will return the most recent write since it has replicas. Whereas in Sql it possess strong consistency.


14) CAP Theorem -> why you can achieve at most two out of three properties?
Consistency (C): Every read operation on the system returns the most recent write
Availability (A): Every request (read or write) receives a response
Partition Tolerance (P): A partition refers to a situation where nodes is failed. The system continues to function, even when network partitions or communication failures occur between nodes

The CAP Theorem states that in a distributed system, you can achieve at most two out of three of the above properties,
Partition Tolerance is Non-Negotiable.

If you prioritize Consistency (C):
The system will block reads or writes to certain parts of the system until the partition is resolved, ensuring that all nodes have the same data. This sacrifices Availability.

If you prioritize Availability (A):
The system will allow reads and writes to proceed even if some parts of the system are out of sync. This sacrifices Consistency.


15) Multitenant
Lets say you have a application where 2 customers is using where a customer can have 1 or more extra feature. So, you will be hosting the application and database for those 2 customers seperately. If customers grows, the admistrative complexity will increase.
So that you can host your application in a single place with horizontal scalling and do the data seperation between customers

Ways of data seperation
- Shared schema with tenant id(seperate tenant id column)
- Schema per tenant
- Database per tenant


16) Will below example wont work, Is this because of immutability in functional programming?
Eg:
int i = 0;
IntStream.range(0, 10).forEach(e -> {
    i = e;  // Trying to modify the local variable `i` inside the lambda
});

No, It nothing to do with Immutability. The error occurs because Java enforces final or effectively final restrictions on local variables used in lambda expressions.This is done to prevent unintended side effects or threading issues.

How?
When the declared variable “I” in parallel streams() or asynchronous processing  will case issue. So java wants it to be effectively final.


17) By keeping produces = MediaType.TEXT_EVENT_STREAM_VALUE as header, makes tomcat web server as reactive?
When we use produces = MediaType.TEXT_EVENT_STREAM_VALUE or request.startAsync(), tomcat can process the data asynchronously but either way it will block a thread.
We can use Netty server as reactive server which wont block a thread


18) Reactive kafka over kafka in springboot?
Spring Boot will automatically use Netty instead of Tomcat, if you're using Reactive Kafka for producing or consuming Kafka messages

If you need to publish multiple message in Kafka, using Reactive Kafka ensures that the HTTP request thread isn’t blocked while the messages are being sent to Kafka, allowing your application to handle more concurrent requests without requiring more threads.


19) cross cutting concerns
They are not related to any specific business logic but are essential for the application's operation. These concerns "cut across" multiple modules or layers of the application.
- Logging
- Security/Authentication
- Transaction management
- Caching
- Error handling

In traditional way, it may lead to scattering and tangling 
Scattering: same code is Scattered accross multiple modules thus leading to duplication
Tangling: These cross cutting code(doesnt do anything with functionality) will be present inside business logic which make code complex

To address this we can make use of AOP (Aspect-Oriented Programming)
AOP allows to modularize cross-cutting concerns into separate units called "aspects" and apply them to the codebase without modifying the core logic.
Eg: Custom Logging using AOP, annotations like, @Transactional, @Cacheable, @PreAuthorize etc...


20) RU in DB
RU - request units
RUs are a proxy for the compute, memory, and IO used to process database operations. It is essentially a unit of measure for the cost of operations in the DB given by cloud provider.
throughput is the capacity of a system to handle data or tasks over a period of time. This throughput calculted for our DB by RU/s

Example of RU Consumption:
1 RU: Read operation using primary key.
5-10 RUs: Writing or updating a 1 KB document (depending on indexing).
50-100 RUs: Running a query that scans through a large number of documents.



